{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7637ed7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T07:06:00.367898Z",
     "iopub.status.busy": "2024-02-07T07:06:00.367406Z",
     "iopub.status.idle": "2024-02-07T07:06:17.104552Z",
     "shell.execute_reply": "2024-02-07T07:06:17.103112Z"
    },
    "papermill": {
     "duration": 16.74434,
     "end_time": "2024-02-07T07:06:17.107485",
     "exception": false,
     "start_time": "2024-02-07T07:06:00.363145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmlb\r\n",
      "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/conda/lib/python3.10/site-packages (from pmlb) (2.2.0)\r\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from pmlb) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from pmlb) (6.0.1)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->pmlb) (1.24.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->pmlb) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->pmlb) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->pmlb) (2023.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.24.0->pmlb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.24.0->pmlb) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.24.0->pmlb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.24.0->pmlb) (2023.11.17)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pmlb) (1.16.0)\r\n",
      "Installing collected packages: pmlb\r\n",
      "Successfully installed pmlb-1.0.1.post3\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pmlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf0cb05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T07:06:17.116237Z",
     "iopub.status.busy": "2024-02-07T07:06:17.115787Z",
     "iopub.status.idle": "2024-02-07T08:29:09.410875Z",
     "shell.execute_reply": "2024-02-07T08:29:09.408475Z"
    },
    "papermill": {
     "duration": 4972.303046,
     "end_time": "2024-02-07T08:29:09.413668",
     "exception": false,
     "start_time": "2024-02-07T07:06:17.110622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: flags\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: flags, Best Pipeline: ('StandardScaler', ['RidgeClassifier', 'KNeighborsClassifier', 'RidgeClassifier', 'LogisticRegression', 'DecisionTreeClassifier'], 'StackingClassifier'), Best Accuracy: 0.44541871921182263, RF Accuracy: 0.46600985221674873, GB Accuracy: 0.42290640394088663, ET Accuracy: 0.4236453201970443\n",
      "Processing dataset: flare\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: flare, Best Pipeline: ('RobustScaler', ['LogisticRegression', 'LogisticRegression', 'RidgeClassifier', 'LinearSVC', 'LinearSVC', 'RidgeClassifier'], 'StackingClassifier'), Best Accuracy: 0.8272409127393646, RF Accuracy: 0.8051805985552114, GB Accuracy: 0.8192363261093911, ET Accuracy: 0.8028345373237012\n",
      "Processing dataset: german\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: german, Best Pipeline: ('MinMaxScaler', ['LogisticRegression', 'RidgeClassifier', 'RidgeClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier'], 'VotingClassifier_hard'), Best Accuracy: 0.7391666666666666, RF Accuracy: 0.75625, GB Accuracy: 0.7387500000000001, ET Accuracy: 0.74\n",
      "Processing dataset: glass\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: glass, Best Pipeline: ('StandardScaler', ['KNeighborsClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'SGDClassifier'], 'VotingClassifier_hard'), Best Accuracy: 0.6699368686868685, RF Accuracy: 0.8053030303030303, GB Accuracy: 0.7191287878787878, ET Accuracy: 0.7865530303030303\n",
      "Processing dataset: glass2\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: glass2, Best Pipeline: ('RobustScaler', ['GaussianNB', 'GaussianNB', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RidgeClassifier', 'DecisionTreeClassifier', 'DecisionTreeClassifier', 'SGDClassifier'], 'StackingClassifier'), Best Accuracy: 0.7517948717948718, RF Accuracy: 0.8461538461538461, GB Accuracy: 0.8076923076923077, ET Accuracy: 0.8384615384615385\n",
      "Processing dataset: haberman\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: haberman, Best Pipeline: ('PCA', ['SGDClassifier', 'KNeighborsClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'LogisticRegression'], 'VotingClassifier_hard'), Best Accuracy: 0.7551303854875285, RF Accuracy: 0.7420918367346939, GB Accuracy: 0.7009353741496598, ET Accuracy: 0.7379251700680272\n",
      "Processing dataset: hayes_roth\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: hayes_roth, Best Pipeline: ('RobustScaler', ['KNeighborsClassifier', 'GaussianNB', 'DecisionTreeClassifier', 'GaussianNB', 'KNeighborsClassifier', 'DecisionTreeClassifier'], 'StackingClassifier'), Best Accuracy: 0.7853128205128204, RF Accuracy: 0.8596923076923076, GB Accuracy: 0.8590769230769231, ET Accuracy: 0.8513846153846154\n",
      "Processing dataset: heart_c\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: heart_c, Best Pipeline: ('StandardScaler', ['RidgeClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'GaussianNB', 'LinearSVC'], 'StackingClassifier'), Best Accuracy: 0.8322392290249433, RF Accuracy: 0.8308673469387754, GB Accuracy: 0.8020408163265307, ET Accuracy: 0.8434523809523811\n",
      "Processing dataset: heart_h\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: heart_h, Best Pipeline: ('RobustScaler', ['RidgeClassifier', 'SGDClassifier', 'KNeighborsClassifier', 'KNeighborsClassifier'], 'StackingClassifier'), Best Accuracy: 0.8093617021276596, RF Accuracy: 0.8085106382978722, GB Accuracy: 0.7872340425531914, ET Accuracy: 0.8\n",
      "Processing dataset: heart_statlog\n",
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Dataset: heart_statlog, Best Pipeline: ('MinMaxScaler', ['LinearSVC', 'LinearSVC', 'LinearSVC', 'KNeighborsClassifier', 'GaussianNB'], 'StackingClassifier'), Best Accuracy: 0.8386187455954898, RF Accuracy: 0.8102536997885835, GB Accuracy: 0.7965116279069767, ET Accuracy: 0.8285412262156449\n",
      "Mean Pipeline Accuracy: 0.7454220921848036\n",
      "Mean RF Accuracy: 0.773031315668107\n",
      "Mean GB Accuracy: 0.7453512609634656\n",
      "Mean ET Accuracy: 0.7652797818905982\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "import random\n",
    "from sklearn.utils import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define grammar\n",
    "grammar = {\n",
    "    'preprocessing': ['StandardScaler', 'RobustScaler', 'MinMaxScaler', 'PCA'],\n",
    "    'classifiers': ['DecisionTreeClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'GaussianNB', 'RidgeClassifier', 'SGDClassifier', 'LinearSVC'],\n",
    "    'combinations': ['VotingClassifier_hard', 'StackingClassifier']\n",
    "}\n",
    "\n",
    "# Genotype to phenotype mapping\n",
    "def genotype_to_phenotype(genotype):\n",
    "    if len(genotype) < 4:\n",
    "        return None\n",
    "    \n",
    "    total_preprocessing = len(grammar['preprocessing'])\n",
    "    total_classifiers = len(grammar['classifiers'])\n",
    "    total_combinations = len(grammar['combinations'])\n",
    "\n",
    "    preprocessing_idx = genotype[0] % total_preprocessing\n",
    "    classifiers_idxs = [idx % total_classifiers for idx in genotype[1:-1]]\n",
    "    combination_idx = genotype[-1] % total_combinations\n",
    "\n",
    "    preprocessing = grammar['preprocessing'][preprocessing_idx]\n",
    "    classifiers = [grammar['classifiers'][idx] for idx in classifiers_idxs]\n",
    "    combination = grammar['combinations'][combination_idx]\n",
    "    \n",
    "    return preprocessing, classifiers, combination\n",
    "\n",
    "# Fitness function with cross-validation\n",
    "def evaluate_pipeline_cv(preprocessing, base_classifiers, combination_method, X, y):\n",
    "    preprocessing = globals()[preprocessing]()\n",
    "    X_transformed = preprocessing.fit_transform(X)\n",
    "    \n",
    "    base_classifier_instances = [globals()[classifier]() for classifier in base_classifiers]\n",
    "    \n",
    "    if combination_method == 'VotingClassifier_hard':\n",
    "        ensemble = VotingClassifier(estimators=[(str(i), clf) for i, clf in enumerate(base_classifier_instances)], voting='hard')\n",
    "    elif combination_method == 'StackingClassifier':\n",
    "        ensemble = StackingClassifier(estimators=[(str(i), clf) for i, clf in enumerate(base_classifier_instances)], final_estimator=LogisticRegression(max_iter=10000))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported combination method.\")\n",
    "    \n",
    "    scores = cross_val_score(ensemble, X_transformed, y, cv=5)  # 5-fold cross-validation\n",
    "    accuracy = np.mean(scores)\n",
    "    return accuracy\n",
    "\n",
    "# Genetic Algorithm parameters\n",
    "population_size = 50\n",
    "num_generations = 15\n",
    "mutation_rate = 0.3\n",
    "crossover_rate = 0.5  # Adjust as needed\n",
    "\n",
    "# Load dataset\n",
    "results = []\n",
    "\n",
    "for dataset_name in pmlb.classification_dataset_names[71:81]:\n",
    "    if dataset_name in ['kddcup', 'mnist','krkopt','adult','coil2000','connect_4','clean2']:  # Skip the datasets named \"kddcup\" and \"mnist\"\n",
    "        continue\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    X, y = pmlb.fetch_data(dataset_name, return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    population = [\n",
    "        [random.randint(0, len(grammar['preprocessing']) + len(grammar['classifiers']) + len(grammar['combinations']) - 1) for _ in range(random.randint(4, 10))]\n",
    "        for _ in range(population_size)\n",
    "    ]\n",
    "\n",
    "    # Evolutionary loop\n",
    "    fitness_scores_list = []\n",
    "    for generation in range(num_generations):\n",
    "        print(f\"Generation {generation + 1}\")\n",
    "        # Convert genotypes to phenotypes\n",
    "        phenotypes = [genotype_to_phenotype(genotype) for genotype in population]\n",
    "        # print(\"Genotypes and Equivalent Phenotypes:\")\n",
    "        # for genotype, phenotype in zip(population, phenotypes):\n",
    "        #     print(f\"Genotype: {genotype}, Phenotype: {phenotype}\")\n",
    "        # Evaluate fitness\n",
    "        fitness_scores = [\n",
    "            evaluate_pipeline_cv(preprocessing, base_classifiers, combination_method, X_train, y_train)\n",
    "            for preprocessing, base_classifiers, combination_method in phenotypes\n",
    "        ]\n",
    "        fitness_scores_list.append(fitness_scores)\n",
    "\n",
    "        # Select parents based on fitness scores (roulette wheel selection)\n",
    "        total_fitness = sum(fitness_scores)\n",
    "        probabilities = [score / total_fitness if total_fitness != 0 else 1/population_size for score in fitness_scores]\n",
    "        parent_indices = np.random.choice(range(population_size), size=population_size, p=probabilities)\n",
    "        parents = [population[i] for i in parent_indices]\n",
    "\n",
    "        # Apply crossover\n",
    "        offspring = []\n",
    "        for i in range(0, population_size, 2):\n",
    "            if random.random() < crossover_rate:\n",
    "                crossover_point = random.randint(1, len(parents[i]) - 1)\n",
    "                offspring1 = parents[i][:crossover_point] + parents[i + 1][crossover_point:]\n",
    "                offspring2 = parents[i + 1][:crossover_point] + parents[i][crossover_point:]\n",
    "                offspring.append(offspring1)\n",
    "                offspring.append(offspring2)\n",
    "            else:\n",
    "                offspring.append(parents[i])\n",
    "                offspring.append(parents[i + 1])\n",
    "\n",
    "        # Apply mutation\n",
    "        for i in range(population_size):\n",
    "            if random.random() < mutation_rate:\n",
    "                # Randomly select one gene to mutate\n",
    "                gene_to_mutate = random.randint(0, len(offspring[i]) - 1)\n",
    "                offspring[i][gene_to_mutate] = random.randint(0, 100)\n",
    "\n",
    "        # Replace old population with new population\n",
    "        population = offspring\n",
    "\n",
    "        # Introduce new random individuals to maintain diversity\n",
    "        while len(population) < population_size:\n",
    "            new_genotype = [random.randint(0, len(grammar['preprocessing']) + len(grammar['classifiers']) + len(grammar['combinations']) - 1) for _ in range(random.randint(4, 10))]\n",
    "            population.append(new_genotype)\n",
    "\n",
    "    # Find best pipeline\n",
    "    best_index = np.argmax(np.mean(fitness_scores_list, axis=0))\n",
    "    best_pipeline = phenotypes[best_index]\n",
    "    best_accuracy = np.mean(fitness_scores_list, axis=0)[best_index]\n",
    "    \n",
    "    # Calculate accuracies for default Random Forest and Gradient Boost classifiers\n",
    "    rf = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "    gb = GradientBoostingClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    gb.fit(X_train, y_train)\n",
    "    rf_accuracy = np.mean(cross_val_score(rf, X_train, y_train, cv=5))\n",
    "    gb_accuracy = np.mean(cross_val_score(gb, X_train, y_train, cv=5))\n",
    "\n",
    "    # Calculate accuracies for Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=42,n_jobs=-1)\n",
    "    et.fit(X_train, y_train)\n",
    "    et_accuracy = np.mean(cross_val_score(et, X_train, y_train, cv=5))\n",
    "\n",
    "    results.append([dataset_name, best_pipeline, best_accuracy, rf_accuracy, gb_accuracy, et_accuracy])\n",
    "    print(f\"Dataset: {dataset_name}, Best Pipeline: {best_pipeline}, Best Accuracy: {best_accuracy}, RF Accuracy: {rf_accuracy}, GB Accuracy: {gb_accuracy}, ET Accuracy: {et_accuracy}\")\n",
    "        \n",
    "# Calculate mean accuracies\n",
    "mean_pipeline_accuracy = np.mean([row[2] for row in results])\n",
    "mean_rf_accuracy = np.mean([row[3] for row in results])\n",
    "mean_gb_accuracy = np.mean([row[4] for row in results])\n",
    "mean_et_accuracy = np.mean([row[5] for row in results])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Pipeline Accuracy: {mean_pipeline_accuracy}\")\n",
    "print(f\"Mean RF Accuracy: {mean_rf_accuracy}\")\n",
    "print(f\"Mean GB Accuracy: {mean_gb_accuracy}\")\n",
    "print(f\"Mean ET Accuracy: {mean_et_accuracy}\")\n",
    "\n",
    "# Store results in a CSV file\n",
    "df = pd.DataFrame(results, columns=['Dataset', 'Best Pipeline', 'Pipeline Accuracy', 'RF Accuracy', 'GB Accuracy', 'ET Accuracy'])\n",
    "df.to_csv('pipeline_results_optimized_with_crossover.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4992.816039,
   "end_time": "2024-02-07T08:29:10.065660",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-07T07:05:57.249621",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
